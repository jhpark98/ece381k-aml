{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "from contextlib import contextmanager\n",
    "\n",
    "def show_memory_usage(name = \"unknown\"):\n",
    "    vm = psutil.virtual_memory()\n",
    "    print(f\"[MEMUSE] memory usage (in {name}): {vm.used/1024/1024:.2f}MB ({vm.percent}%)\")\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    show_memory_usage(f\"before {name}\")\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f\"[{name}] {elapsed:.3f}sec\")\n",
    "    show_memory_usage(f\"after {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/ziyangtan/Documents/applied_ml/2rd_solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS_DEBUG True\n",
      "train_path /Users/ziyangtan/Documents/applied_ml/2rd_solution/data/data_raw/train_series.parquet\n",
      "train_target_path /Users/ziyangtan/Documents/applied_ml/2rd_solution/data/data_raw/train_events.csv\n",
      "test_path /Users/ziyangtan/Documents/applied_ml/2rd_solution/data/data_raw/test_series.parquet\n",
      "sample_submission_path /Users/ziyangtan/Documents/applied_ml/2rd_solution/data/data_raw/sample_submission.csv\n",
      "preprocess_dir data_processed/\n",
      "weight_dir_1dcnn model/weights/\n",
      "weight_dir_lgbm model/lgbm_models/\n",
      "inputs_2nd data_processed/df_second_model.feather\n",
      "steps_per_sec 0.2\n",
      "step_for_1min 12.0\n",
      "step_for_15min 180.0\n",
      "step_for_30min 360.0\n",
      "step_for_a_day 17280.0\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # self.train_path = '../data/data_raw/train_series.parquet'\n",
    "        # self.train_target_path = '../data/data_raw/train_events.csv'\n",
    "        # self.test_path = '../data/data_raw/test_series.parquet'\n",
    "        # self.sample_submission_path = '../data/data_raw/sample_submission.csv'\n",
    "        # self.preprocess_dir = '../data/data_processed'\n",
    "        self.steps_per_sec = 0.2\n",
    "        self.step_for_a_day = 60 * self.steps_per_sec * 60 * 24\n",
    "        self.step_for_30min = 60 * self.steps_per_sec * 30\n",
    "        self.step_for_15min = 60 * self.steps_per_sec * 15\n",
    "        self.step_for_1min = 60 * self.steps_per_sec\n",
    "\n",
    "    def from_json(self, json_path):\n",
    "        json_data = json.load(open(json_path))\n",
    "        for k, v in json_data.items():\n",
    "            print(k, v)\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "setting_file = \"SETTINGS.json\"\n",
    "Cfg = Config().from_json(setting_file)\n",
    "os.makedirs(Cfg.preprocess_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "cimport cython\n",
    "\n",
    "def cumsum_morethan_zero(cnp.ndarray[cnp.float64_t, ndim=1] x):\n",
    "    cdef int i, n\n",
    "    n = x.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] y = np.zeros(n)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] y_rev = np.zeros(n)\n",
    "    y[0] = x[0]\n",
    "    for i in range(1, n):\n",
    "        if x[i] == 0:\n",
    "            y[i] = 0\n",
    "        else:\n",
    "            y[i] = y[i-1] + x[i]\n",
    "    y_rev[-1] = y[-1]\n",
    "    for i in range(n-2, -1, -1):\n",
    "        if y_rev[i+1] > y[i]:\n",
    "            if x[i] == 0:\n",
    "                y_rev[i] = 0\n",
    "            else:\n",
    "                y_rev[i] = y_rev[i+1]\n",
    "        else:\n",
    "            y_rev[i] = y[i]\n",
    "    return y_rev\n",
    "\n",
    "def easy_convolve(cnp.ndarray[cnp.float64_t, ndim=1] x, int filter_size):\n",
    "    \"\"\"\n",
    "    padding same, kernel is ones\n",
    "    \"\"\"\n",
    "    cdef int i, j, n, p, m\n",
    "    m = filter_size - 1\n",
    "    p = m // 2\n",
    "    n = x.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] x_p = np.zeros(n+2*p)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] y = np.zeros(n)\n",
    "    x_p[p:n+p] = x\n",
    "\n",
    "    for j in range(filter_size):\n",
    "        y[0] += x_p[j]\n",
    "\n",
    "    for i in range(1, n):# filter_size, n+p+p-filter_size+1):\n",
    "        y[i] = x_p[i+m] + y[i-1] - x_p[i-1]\n",
    "    return y\n",
    "\n",
    "def minimum(cnp.ndarray[cnp.float64_t, ndim=1] x, cnp.float64_t maxval):\n",
    "    cdef int i, n\n",
    "    n = x.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        y[i] = min(x[i], maxval)\n",
    "    return y\n",
    "\n",
    "def easy_closing(cnp.ndarray[cnp.float64_t, ndim=1] x, int filter_size):\n",
    "    \"\"\"\n",
    "    closing = dilation -> erosion\n",
    "    padding same, kernel is ones, x is 0 or 1\n",
    "    \"\"\"\n",
    "    x = easy_convolve(x, filter_size)\n",
    "    x = minimum(x, 1)\n",
    "    x = 1 - x\n",
    "    x = easy_convolve(x, filter_size)\n",
    "    x = minimum(x, 1)\n",
    "    x = 1 - x\n",
    "    return x\n",
    "\n",
    "def easy_closing_q(cnp.ndarray[cnp.float64_t, ndim=1] x, int filter_size):\n",
    "    \"\"\"\n",
    "    closing = dilation -> erosion\n",
    "    padding same, kernel is ones, x is 0 or 1\n",
    "    少し早いけどわかりにくい…。\n",
    "    \"\"\"\n",
    "    cdef int i, j, n, p, m\n",
    "    m = filter_size - 1\n",
    "    p = m // 2\n",
    "    n = x.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] x_p = np.zeros(n+2*p)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] y_p = np.zeros(n+2*p)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] y = np.zeros(n)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] z = np.zeros(n)\n",
    "    \n",
    "    x_p[p:n+p] = x\n",
    "    for j in range(filter_size):\n",
    "        y[0] += x_p[j]\n",
    "    for i in range(1, n):# filter_size, n+p+p-filter_size+1):\n",
    "        y[i] = x_p[i+m] + y[i-1] - x_p[i-1]\n",
    "    for i in range(n):\n",
    "        y[i] = 1 - min(y[i], 1)\n",
    "    \n",
    "    y_p[p:n+p] = y\n",
    "    for j in range(filter_size):\n",
    "        z[0] += y_p[j]\n",
    "    for i in range(1, n):# filter_size, n+p+p-filter_size+1):\n",
    "        z[i] = y_p[i+m] + z[i-1] - y_p[i-1]\n",
    "    for i in range(n):\n",
    "        z[i] = 1 - min(z[i], 1)\n",
    "    \n",
    "    return z\n",
    "\n",
    "\n",
    "def _detect_peak(cnp.ndarray[cnp.float64_t, ndim=1] x, int k):\n",
    "    cdef int n = x.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] max_array = np.zeros(n, dtype=np.float64)\n",
    "    cdef cnp.ndarray[cnp.int32_t, ndim=1] max_indices = np.zeros(n, dtype=np.int32)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] result = np.zeros(n, dtype=np.float64)\n",
    "    cdef int i, j, start, end, max_index\n",
    "    \n",
    "    # calculate max values in each window\n",
    "    for i in range(n):\n",
    "        start = max(0, i - k)\n",
    "        end = min(n, i + k + 1)\n",
    "        max_index = start\n",
    "        for j in range(start, end):\n",
    "            if x[j] > x[max_index]:\n",
    "                max_index = j\n",
    "        max_array[i] = x[max_index]\n",
    "        max_indices[i] = max_index\n",
    "    \n",
    "    # set peak values to 1\n",
    "    for i in range(n):\n",
    "        if x[i] == max_array[max_indices[i]]:\n",
    "            result[i] = 1.0\n",
    "    \n",
    "    return max_array\n",
    "\n",
    "def _detect_peak_r(cnp.ndarray[cnp.float64_t, ndim=1] x, int k):\n",
    "    cdef int n = x.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] max_array = np.zeros(n, dtype=np.float64)\n",
    "    cdef cnp.ndarray[cnp.int32_t, ndim=1] max_indices = np.zeros(n, dtype=np.int32)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] result = np.zeros(n, dtype=np.float64)\n",
    "    cdef int i, j, start, end, max_index\n",
    "    \n",
    "    # calculate max values in first window\n",
    "    max_index = 0\n",
    "    for i in range(k):\n",
    "        if x[i] > x[max_index]:\n",
    "            max_index = i\n",
    "    max_array[k-1] = x[max_index]\n",
    "    max_indices[k-1] = max_index\n",
    "    \n",
    "    # calculate max values in each window\n",
    "    for i in range(k, n):\n",
    "        start = i - k\n",
    "        end = i\n",
    "        if max_index == start - 1:\n",
    "            max_index = start\n",
    "            for j in range(start, end):\n",
    "                if x[j] > x[max_index]:\n",
    "                    max_index = j\n",
    "        else:\n",
    "            if x[i] > x[max_index]:\n",
    "                max_index = i\n",
    "        max_array[i] = x[max_index]\n",
    "        max_indices[i] = max_index\n",
    "    \n",
    "    # set peak values to 1\n",
    "    for i in range(n):\n",
    "        if x[i] == max_array[max_indices[i]]:\n",
    "            result[i] = 1.0\n",
    "    \n",
    "    return max_array\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def detect_peak_kmat(cnp.ndarray[cnp.float64_t, ndim=1] x, int k):\n",
    "    cdef int n = x.shape[0]\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] max_array = np.zeros(n, dtype=np.float64)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] result_val = np.zeros(n, dtype=np.float64)\n",
    "    cdef cnp.ndarray[cnp.float64_t, ndim=1] result = np.zeros(n, dtype=np.float64)\n",
    "    cdef int i, j, start, end, max_index, half_k\n",
    "\n",
    "    half_k = k // 2\n",
    "    for i in range(half_k, n-half_k):\n",
    "        result[i] = 1\n",
    "        result_val[i] = x[i]\n",
    "        for j in range(1, half_k+1):\n",
    "            if x[i] < x[i-j]:\n",
    "                result[i] = 0\n",
    "                result_val[i] = 0\n",
    "                break\n",
    "            if x[i] < x[i+j]:\n",
    "                result[i] = 0\n",
    "                result_val[i] = 0\n",
    "                break\n",
    "    return result, result_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_train_target_by_id(df_train, df_target, id_no):\n",
    "    return df_train[df_train['series_id']==id_no], df_target[df_target['series_id']==id_no]\n",
    "\n",
    "def anglez_enmo_to_az(enmo, anglez):\n",
    "    # anglezのtanをとる。anglezは-90~90\n",
    "    a = np.clip(np.tan(anglez / 180 * np.pi), -0.99999, 0.99999)\n",
    "    # a = np.tan(anglez / 180 * np.pi)\n",
    "    b = (enmo + 1)**2\n",
    "    axay_sqsum = b / (1 + a**2)\n",
    "    axay = np.sqrt(axay_sqsum)\n",
    "    az = a * axay\n",
    "    return az, axay\n",
    "\n",
    "def make_features(df_train_id):\n",
    "    az, axay = anglez_enmo_to_az(df_train_id[\"enmo\"].values, df_train_id[\"anglez\"].values)\n",
    "    df_train_id[\"accz\"] = az\n",
    "    df_train_id[\"accaxay\"] = axay\n",
    "    return df_train_id\n",
    "\n",
    "def find_sensor_error(df_train_id, column='anglez'):\n",
    "    \"\"\"\n",
    "    df_train_idは特定ユーザのデータ\n",
    "    日にちごとに分割したうえで、同じ時間帯のデータの差をとる\n",
    "    差がゼロになる部分の数をカウントした列を追加する\n",
    "    \"\"\"\n",
    "    def padding(x, left, right, value=0):\n",
    "        return np.pad(x, (left, right), 'constant', constant_values=(value, value))\n",
    "\n",
    "\n",
    "    x = df_train_id['daily_step'].values\n",
    "    y = df_train_id[column].values\n",
    "    mask = np.ones_like(y)\n",
    "    tar = df_train_id['target'].values * (df_train_id['target'].values > -1e-7)# 一時的。効果の有無を確認したい\n",
    "    pad_left = int(x[0])\n",
    "    pad_right = int(Cfg.step_for_a_day) -1 - int(x[-1]) % int(Cfg.step_for_a_day)\n",
    "    \n",
    "    x = padding(x, pad_left, pad_right, value=0)\n",
    "    y = padding(y, pad_left, pad_right, value=0)\n",
    "    y_dif = padding(np.abs(y[1:] - y[:-1]), 1, 0, value=0)\n",
    "    mask = padding(mask, pad_left, pad_right, value=0)\n",
    "    tar = padding(tar, pad_left, pad_right, value=0)\n",
    "\n",
    "\n",
    "    # reshape to (num_day, step_for_a_day)\n",
    "    x = x.reshape(-1, int(Cfg.step_for_a_day))\n",
    "    y = y.reshape(-1, int(Cfg.step_for_a_day))\n",
    "    y_dif = y_dif.reshape(-1, int(Cfg.step_for_a_day))\n",
    "    mask = mask.reshape(-1, int(Cfg.step_for_a_day))\n",
    "    tar = tar.reshape(-1, int(Cfg.step_for_a_day))\n",
    "    day_counter = np.cumsum(mask, axis=0) # (num_day, step_for_a_day)\n",
    "\n",
    "    # メモリ注意。\n",
    "    delta_matrix = y[np.newaxis, :, :] - y[:, np.newaxis, :] # (num_day, num_day, step_for_a_day)\n",
    "    mask_matrix = mask[np.newaxis, :, :] * mask[:, np.newaxis, :] # (num_day, num_day, step_for_a_day)\n",
    "    delta_matrix_full = (delta_matrix==0) * mask_matrix # where delta is zero except for the padding area\n",
    "    \n",
    "    delta_matrix = np.sum(delta_matrix_full, axis=0) - 1 # (num_day, step_for_a_day). 同じデータ同士の差は0になるので-1\n",
    "    mask_matrix = np.sum(mask_matrix, axis=0) # (num_day, step_for_a_day)\n",
    "    nan_counter = np.cumsum(delta_matrix > 0, axis=0) # (num_day, step_for_a_day) 初回のnan風なものは案外ラベルがついている？\n",
    "    # print(nan_counter.shape)\n",
    "    # ↑ミスってるので修正(これだと初日情報つかんでるかも…？これは有効に働いてるのか…？とりあえずdiagの部分だけを使う)\n",
    "    # nan_counter = np.cumsum(delta_matrix_full, axis=0) # (num_day, step_for_a_day) 初回のnan風なものは案外ラベルがついている？\n",
    "    # num_day = nan_counter.shape[0]\n",
    "    # nan_counter = nan_counter[np.arange(num_day), np.arange(num_day), :]# np.diagonal(nan_counter, axis1=0, axis2=1)\n",
    "\n",
    "\n",
    "\n",
    "    nan_exist_other_day = np.any(delta_matrix > 0, axis=0, keepdims=True) # (1, step_for_a_day)\n",
    "    nan_exist_other_day = np.tile(nan_exist_other_day, (delta_matrix.shape[0], 1)) # (num_day, step_for_a_day)\n",
    "\n",
    "\n",
    "    maybe_not_nan = delta_matrix == 0\n",
    "    valid = mask * maybe_not_nan\n",
    "    y_valid = y_dif * maybe_not_nan # (num_day, step_for_a_day) ★一時的にy_difを使う。\n",
    "    y_sum = np.sum(y_valid, axis=0, keepdims=True) # (1, step_for_a_day)\n",
    "    y_mean = y_sum / (np.sum(valid, axis=0, keepdims=True)+1e-7) # (1, step_for_a_day)\n",
    "    y_dev = (y_valid - y_mean) * valid # (num_day, step_for_a_day)\n",
    "    y_std = np.sqrt(np.sum(y_dev**2, axis=0, keepdims=True) / (np.sum(valid, axis=0, keepdims=True)+1e-7)) # (1, step_for_a_day)\n",
    "    # mean, stdをtileして、yと同じshapeにする\n",
    "    y_mean = np.tile(y_mean, (y.shape[0], 1))\n",
    "    y_std = np.tile(y_std, (y.shape[0], 1)) # (num_day, step_for_a_day)\n",
    "\n",
    "    tar_sum = np.sum(tar, axis=0, keepdims=True) # (1, step_for_a_day)\n",
    "    tar_other = (tar_sum - tar) / (np.sum(mask, axis=0, keepdims=True) - mask + 1e-7) # (num_day, step_for_a_day)\n",
    "\n",
    "    # flatten\n",
    "    delta_matrix = delta_matrix.reshape(-1)\n",
    "    mask_matrix = mask_matrix.reshape(-1)\n",
    "    day_counter = day_counter.reshape(-1)\n",
    "    nan_counter = nan_counter.reshape(-1)\n",
    "    nan_exist_other_day = nan_exist_other_day.reshape(-1)\n",
    "    y_mean = y_mean.reshape(-1)\n",
    "    y_std = y_std.reshape(-1)\n",
    "    tar_other = tar_other.reshape(-1)\n",
    "\n",
    "    # left, rightのpadding部分を除く\n",
    "    start = pad_left\n",
    "    end = -pad_right if pad_right > 0 else len(delta_matrix)\n",
    "    delta_matrix = delta_matrix[start:end]\n",
    "    mask_matrix = mask_matrix[start:end]\n",
    "    day_counter = day_counter[start:end]\n",
    "    nan_counter = nan_counter[start:end]\n",
    "    nan_exist_other_day = nan_exist_other_day[start:end]\n",
    "    y_mean = y_mean[start:end]\n",
    "    y_std = y_std[start:end]\n",
    "    tar_other = tar_other[start:end]\n",
    "\n",
    "    df_train_id[column+\"_numrepeat\"] = delta_matrix\n",
    "    df_train_id[column+\"_daycount\"] = mask_matrix\n",
    "    df_train_id[column+\"_daycounter\"] = day_counter\n",
    "    df_train_id[column+\"_nancounter\"] = nan_counter\n",
    "    df_train_id[column+\"_nanexist\"] = nan_exist_other_day\n",
    "    df_train_id[column+\"_daymean\"] = y_mean\n",
    "    df_train_id[column+\"_daystd\"] = y_std\n",
    "    df_train_id[column+\"_tarother\"] = tar_other\n",
    "\n",
    "    # smoothing(膨張収縮処理)で超短期を埋めておく。とりあえず5stepクロージング。    \n",
    "    df_train_id[column+\"_simpleerror\"] = easy_closing_q((delta_matrix > 0).astype(np.float64),  5) # 5step\n",
    "    df_train_id[column+\"_simpleerror_span\"] = cumsum_morethan_zero(df_train_id[column+\"_simpleerror\"].values)\n",
    "    df_train_id[column+\"_simpleerror_v2\"] = df_train_id[column+\"_simpleerror\"].astype(int) + (df_train_id[column+\"_simpleerror_span\"] > Cfg.step_for_30min).astype(int) + (df_train_id[column+\"_simpleerror_span\"] > (Cfg.step_for_30min*2)).astype(int) # \n",
    "\n",
    "    return df_train_id\n",
    "\n",
    "def make_binary_target(df_train_id, df_target_id, id_no):\n",
    "    df_train_id['target'] = -1\n",
    "    # df_target_idを順番に見ていって、onset と wakeupの間を0に、wakeupとonsetの間を1にする\n",
    "    # ただし、wakeupのあとのonsetがnanになっている場合は、-1のままにする\n",
    "    current_state = -1\n",
    "    current_step = 0\n",
    "    # nanでも直後の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "    continue_length = int(Cfg.step_for_30min*4)\n",
    "\n",
    "    for total_step, event_type, night_no in zip(df_target_id['step'].values, df_target_id['event'].values, df_target_id['night'].values):\n",
    "        tmp = current_state\n",
    "        data_exist = not np.isnan(total_step)\n",
    "        if event_type == 'onset' and data_exist:\n",
    "            if current_state == 1 or current_state == -1:\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < total_step), 'target'] = 1\n",
    "            if current_state == -2: # nan before onset. 直前がnanでもevent変化前の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "                df_train_id.loc[(df_train_id['step'] >= np.maximum(total_step - continue_length, 0)) & (df_train_id['step'] < total_step), 'target'] = 1\n",
    "            current_state = 0\n",
    "            current_step = total_step\n",
    "        elif event_type == 'wakeup' and data_exist:\n",
    "            if current_state == 0 or current_state == -1: # 初回wakeupはあるのか？\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < total_step), 'target'] = 0\n",
    "            if current_state == -2: # nan before wakeup. 直前がnanでもevent変化前の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "                df_train_id.loc[(df_train_id['step'] >= np.maximum(total_step - continue_length, 0)) & (df_train_id['step'] < total_step), 'target'] = 0\n",
    "            current_state = 1\n",
    "            current_step = total_step\n",
    "        elif not data_exist: # nan\n",
    "            # 直後の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "            if current_state == 1: # nan after wakeup\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 1\n",
    "            elif current_state == 0: # nan after onset\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 0\n",
    "\n",
    "            current_state = -2\n",
    "        # print(tmp, \"->\", event_type, \"->\", current_state, data_exist, total_step)\n",
    "        \n",
    "    # 最後、終了時点の分も追加\n",
    "    # if not id_no == 'a596ad0b82aa':# これ以外もだめっぽい…。ないやつは何なんだ。\n",
    "    #     if current_state == 1:\n",
    "    #         df_train_id.loc[(df_train_id['step'] >= current_step), 'target'] = 1\n",
    "    #     elif current_state == 0:\n",
    "    #         df_train_id.loc[(df_train_id['step'] >= current_step), 'target'] = 0\n",
    "    # else:\n",
    "    #     print(\"-----------------------------------\"*10)\n",
    "    #     print(\"id a596ad0b82aa has no wakeup event in last N days.\")\n",
    "\n",
    "\n",
    "    # 学習時にレンジ絞るようにstep_for_trainを作ったけど、現状使わないことにしている。\n",
    "    if current_state == 1: # nan after wakeup\n",
    "        df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 1\n",
    "        end_step_for_train = current_step+continue_length\n",
    "    elif current_state == 0: # nan after onset\n",
    "        df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 0\n",
    "        end_step_for_train = current_step+continue_length\n",
    "    # if current_state == 1:\n",
    "    #     df_train_id.loc[(df_train_id['step'] >= current_step), 'target'] = 1\n",
    "    #     end_step_for_train = current_step+continue_length\n",
    "    # elif current_state == 0:\n",
    "    #     df_train_id.loc[(df_train_id['step'] >= current_step), 'target'] = 0\n",
    "    #     end_step_for_train = current_step+continue_length\n",
    "    elif current_state == -2:\n",
    "        end_step_for_train = (night_no - 1) * Cfg.step_for_a_day\n",
    "\n",
    "    \n",
    "    return df_train_id, end_step_for_train\n",
    "\n",
    "def make_multilabel_target(df_train_id, df_target_id, id_no):\n",
    "    df_train_id['target'] = -1\n",
    "    df_train_id['target_sw'] = 0\n",
    "    sw_step_range = [i-1 for i in [1, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360]][::-1]\n",
    "    sw_labels = [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1][::-1] # multi labelしてみる 11はど真ん中。使用は未定\n",
    "\n",
    "    # df_target_idを順番に見ていって、onset と wakeupの間を0に、wakeupとonsetの間を1にする\n",
    "    # ただし、wakeupのあとのonsetがnanになっている場合は、-1のままにする\n",
    "    current_state = -1\n",
    "    current_step = 0\n",
    "    # nanでも直後の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "    continue_length = int(Cfg.step_for_30min*4)\n",
    "    max_step = df_target_id['step'].values.max()\n",
    "\n",
    "    for total_step, event_type, night_no in zip(df_target_id['step'].values, df_target_id['event'].values, df_target_id['night'].values):\n",
    "        tmp = current_state\n",
    "        data_exist = not np.isnan(total_step)\n",
    "        if event_type == 'onset' and data_exist:\n",
    "            if current_state == 1 or current_state == -1:\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < total_step), 'target'] = 1\n",
    "            if current_state == -2: # nan before onset. 直前がnanでもevent変化前の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "                df_train_id.loc[(df_train_id['step'] >= np.maximum(total_step - continue_length, 0)) & (df_train_id['step'] < total_step), 'target'] = 1\n",
    "            current_state = 0\n",
    "            current_step = total_step\n",
    "\n",
    "            # target_swは、状態変化のタイミングでstepが合致する前後のデータを数値に変換する\n",
    "            for label_range, sw_label in zip(sw_step_range, sw_labels): # 広い範囲から順番に。\n",
    "                df_train_id.loc[(df_train_id['step'] >= (total_step - label_range)) & (df_train_id['step'] <= (total_step + label_range)), 'target_sw'] = sw_label\n",
    "\n",
    "\n",
    "        elif event_type == 'wakeup' and data_exist:\n",
    "            if current_state == 0 or current_state == -1: # 初回wakeupはあるのか？\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < total_step), 'target'] = 0\n",
    "            if current_state == -2: # nan before wakeup. 直前がnanでもevent変化前の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "                df_train_id.loc[(df_train_id['step'] >= np.maximum(total_step - continue_length, 0)) & (df_train_id['step'] < total_step), 'target'] = 0\n",
    "            current_state = 1\n",
    "            current_step = total_step\n",
    "\n",
    "            # target_swは、状態変化のタイミングでstepが合致する前後のデータを数値に変換する\n",
    "            for label_range, sw_label in zip(sw_step_range, sw_labels): # 広い範囲から順番に。\n",
    "                df_train_id.loc[(df_train_id['step'] >= (total_step - label_range)) & (df_train_id['step'] <= (total_step + label_range)), 'target_sw'] = sw_label\n",
    "\n",
    "        elif not data_exist: # nan\n",
    "            # 直後の1-2時間ぐらいは前の状態が継続していると考えられる\n",
    "            if current_state == 1: # nan after wakeup\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 1\n",
    "            elif current_state == 0: # nan after onset\n",
    "                df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 0\n",
    "\n",
    "            current_state = -2\n",
    "        # print(tmp, \"->\", event_type, \"->\", current_state, data_exist, total_step)\n",
    "        \n",
    "\n",
    "    # 学習時にレンジ絞るようにstep_for_trainを作ったけど、現状使わないことにしている。\n",
    "    if current_state == 1: # nan after wakeup\n",
    "        df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 1\n",
    "        end_step_for_train = current_step+continue_length\n",
    "    elif current_state == 0: # nan after onset\n",
    "        df_train_id.loc[(df_train_id['step'] >= current_step) & (df_train_id['step'] < current_step+continue_length), 'target'] = 0\n",
    "        end_step_for_train = current_step+continue_length\n",
    "    # if current_state == 1:\n",
    "    #     df_train_id.loc[(df_train_id['step'] >= current_step), 'target'] = 1\n",
    "    #     end_step_for_train = current_step+continue_length\n",
    "    # elif current_state == 0:\n",
    "    #     df_train_id.loc[(df_train_id['step'] >= current_step), 'target'] = 0\n",
    "    #     end_step_for_train = current_step+continue_length\n",
    "    elif current_state == -2:\n",
    "        end_step_for_train = (night_no - 1) * Cfg.step_for_a_day\n",
    "\n",
    "    \n",
    "    return df_train_id, end_step_for_train\n",
    "\n",
    "def prerprocess_inputs_for_mlmodel(df_train_id):\n",
    "    df_train_id[\"daily_step\"] = (df_train_id[\"daily_step\"] / Cfg.step_for_a_day).astype(np.float32)\n",
    "    df_train_id[\"anglez\"] = (df_train_id[\"anglez\"] / 90).astype(np.float32)\n",
    "    df_train_id[\"anglez_simpleerror\"] = df_train_id[\"anglez_simpleerror\"].astype(np.float32)\n",
    "    # anglez_shimpleerror_spanはlog1pをとっておく\n",
    "    df_train_id[\"anglez_simpleerror_span\"] = np.clip(np.log1p(df_train_id[\"anglez_simpleerror_span\"]) / 10, 0, 1).astype(np.float32)\n",
    "    df_train_id[\"anglez_nanexist\"] = df_train_id[\"anglez_nanexist\"].astype(np.float32)\n",
    "    df_train_id[\"anglez_daystd\"] = np.clip(df_train_id[\"anglez_daystd\"] / 90, 0, 2).astype(np.float32)\n",
    "    df_train_id[\"anglez_daymean\"] = np.clip(df_train_id[\"anglez_daymean\"] / 90, 0, 2).astype(np.float32)\n",
    "    df_train_id[\"anglez_daycounter\"] = (df_train_id[\"anglez_daycounter\"] / df_train_id[\"anglez_daycounter\"].max()).astype(np.float32)\n",
    "    df_train_id[\"anglez_nancounter\"] = (df_train_id[\"anglez_nancounter\"]>2).astype(np.float32)\n",
    "    # df_train_id[\"anglez_nancounter\"] = np.clip(df_train_id[\"anglez_nancounter\"]-2, -1, 1).astype(np.float32)\n",
    "    # df_train_id[\"anglez_tarother\"] = np.clip(df_train_id[\"anglez_tarother\"], 0, 1).astype(np.float32)\n",
    "    max_daystd = np.max(df_train_id[\"anglez_daystd\"].values)\n",
    "    max_daymean = np.max(df_train_id[\"anglez_daymean\"].values)\n",
    "    if max_daystd > 10:\n",
    "        print(\"max_daystd > 10\", max_daystd)\n",
    "    if max_daymean > 10:\n",
    "        print(\"max_daymean > 10\", max_daymean)\n",
    "        \n",
    "\n",
    "    df_train_id[\"enmo\"] = np.clip(np.log1p(df_train_id[\"enmo\"]), 0, 5).astype(np.float32)\n",
    "    df_train_id[\"accz\"] = np.clip(df_train_id[\"accz\"], -2, 2).astype(np.float32)\n",
    "    df_train_id[\"accaxay\"] = np.clip(df_train_id[\"accaxay\"], 0, 3).astype(np.float32)\n",
    "\n",
    "    df_train_id[\"step_count\"] = (df_train_id[\"step\"]/df_train_id[\"step\"].max()).astype(np.float32)\n",
    "    df_train_id[\"dayofweek\"] = (df_train_id[\"dayofweek\"] / 7.).astype(np.float32)\n",
    "\n",
    "    df_train_id[\"target_sw\"] = df_train_id[\"target_sw\"].astype(np.float32)\n",
    "    df_train_id[\"target\"] = df_train_id[\"target\"].astype(np.float32)\n",
    "    return df_train_id\n",
    "\n",
    "def connect_2_arrays(first_array, second_array):\n",
    "    end_step_0 = first_array[-1,0]\n",
    "    initial_step_1 = second_array[0,0]\n",
    "    # print(first_array[-1,0], second_array[0,0])\n",
    "    if end_step_0 >= initial_step_1:\n",
    "        offset = int((end_step_0 - initial_step_1) * Cfg.step_for_a_day)\n",
    "        second_array = second_array[offset:]\n",
    "    else:\n",
    "        offset = int((1 - initial_step_1 + end_step_0) * Cfg.step_for_a_day)\n",
    "        second_array = second_array[offset:]\n",
    "        # print(\"offset2nd\", offset)\n",
    "    # print(first_array[-1,0], second_array[0,0], offset)\n",
    "    return np.concatenate([first_array, second_array], axis=0)\n",
    "\n",
    "def generate_data(processed_array, id_no, days_to_generate_ratio=0.15, min_split_minutes=30, max_split_minutes=60, save_dir=None, plot=False, second_array=None, seed_no=111):\n",
    "    if second_array is not None:\n",
    "        processed_array = connect_2_arrays(processed_array, second_array)\n",
    "    np.random.seed(seed_no)\n",
    "    save_dir = save_dir or Cfg.gen_data_dir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_path = os.path.join(save_dir, f\"id_{id_no}_feature.npy\")\n",
    "    file_step_path = os.path.join(save_dir, f\"id_{id_no}_step.npy\")\n",
    "    file_path_meta = os.path.join(save_dir, f\"id_{id_no}_meta.json\")\n",
    "    days_to_generate = max(int((days_to_generate_ratio * processed_array.shape[0]) / int(Cfg.step_for_a_day)), 1)\n",
    "\n",
    "    def blend_dataset(processed_array):\n",
    "        step_length = processed_array.shape[0]\n",
    "        day_length = int(step_length // int(Cfg.step_for_a_day))\n",
    "        residual_step = int(step_length % int(Cfg.step_for_a_day))\n",
    "        start =  np.random.randint(0, residual_step) if residual_step > 0 else 0\n",
    "        end = step_length - residual_step + start\n",
    "        processed_array = processed_array[start:end].reshape(day_length, int(Cfg.step_for_a_day), 12)\n",
    "\n",
    "        generated_array = []\n",
    "        step_to_generate = int(Cfg.step_for_a_day * days_to_generate)\n",
    "        total_start = 0\n",
    "        total_end = 0\n",
    "        while total_start < step_to_generate:\n",
    "            start = 0\n",
    "            end = 0\n",
    "            while end < int(Cfg.step_for_a_day):\n",
    "                gen_step = np.minimum(np.random.randint(min_split_minutes, max_split_minutes) * int(Cfg.step_for_1min), step_to_generate - total_start)\n",
    "                end = min(start + gen_step, int(Cfg.step_for_a_day))\n",
    "                gen_step = end - start\n",
    "                total_end = total_start + gen_step\n",
    "                day_idx = np.random.randint(0, day_length)\n",
    "                generated_array.append(processed_array[day_idx, start:end, :])\n",
    "                start = end\n",
    "                total_start = total_end\n",
    "                # print(end, total_start, step_to_generate)\n",
    "                # time.sleep(0.1)\n",
    "        generated_array = np.concatenate(generated_array, axis=0)\n",
    "        return generated_array\n",
    "\n",
    "    \n",
    "    def remake_target(target_binary):\n",
    "        state_change = (np.pad(target_binary[:-1] - target_binary[1:], (1,0), 'constant', constant_values=(0, 0))).astype(int)\n",
    "        state_valid = np.pad((target_binary[:-1] >= 0) * (target_binary[1:]>=0), (1,0), 'constant', constant_values=(0, 0))\n",
    "        state_change = state_change * state_valid\n",
    "        # plt.plot(state_change)\n",
    "        # plt.show()\n",
    "        \n",
    "        # state changeは-1,0,1の行列。-1が0->1のwakeup, 1が1->0のonset。\n",
    "        # {\"state\": \"sleep\", \"start\": idx, \"duration\": next_idx - idx}のような形式で整理する\n",
    "        states = []\n",
    "        current_idx = 0\n",
    "        previous_continue = False\n",
    "        # min_duration = int(Cfg.step_for_30min)\n",
    "        min_duration = int(int(Cfg.step_for_30min) * 0.5)\n",
    "        if target_binary[0] == 0:\n",
    "            current_state = \"sleep\"\n",
    "        elif target_binary[0] == 1:\n",
    "            current_state = \"awake\"\n",
    "        else:\n",
    "            current_state = \"nan\"\n",
    "        while True:\n",
    "            idx = np.argmax((np.abs(state_change)))\n",
    "            if state_change[idx] == 0:\n",
    "                if not previous_continue:\n",
    "                    states.append({\"state\": current_state, \"start\": current_idx, \"duration\": len(state_change) - current_idx})\n",
    "                else:\n",
    "                    states[-1][\"duration\"] += len(state_change) - states[-1][\"start\"]\n",
    "                break\n",
    "            if state_change[idx] == -1:\n",
    "                state_change[idx] = 0\n",
    "                if idx < min_duration and current_idx > 0:\n",
    "                    if not previous_continue: # 二回連続で短い場合は無視\n",
    "                        previous_continue = True\n",
    "                        continue\n",
    "                state_change = state_change[idx:]\n",
    "                # if current_state in [\"sleep\", \"nan\"]: # 前の状態と合致しない場合(nan)は無視\n",
    "                if not previous_continue:\n",
    "                    states.append({\"state\": \"sleep\", \"start\": current_idx, \"duration\": idx})\n",
    "                else:\n",
    "                    states[-1][\"duration\"] += idx\n",
    "                previous_continue = False\n",
    "                current_idx += idx\n",
    "                current_state = \"awake\"\n",
    "                continue\n",
    "            if state_change[idx] == 1:\n",
    "                state_change[idx] = 0\n",
    "                if idx < min_duration and current_idx > 0: # 初回は短くても許容する\n",
    "                    if not previous_continue:\n",
    "                        previous_continue = True\n",
    "                        continue\n",
    "                state_change = state_change[idx:]\n",
    "                # if current_state in [\"awake\", \"nan\"]:\n",
    "                if not previous_continue:\n",
    "                    states.append({\"state\": \"awake\", \"start\": current_idx, \"duration\": idx})\n",
    "                else:\n",
    "                    states[-1][\"duration\"] += idx\n",
    "                previous_continue = False\n",
    "                current_idx += idx\n",
    "                current_state = \"sleep\"\n",
    "                continue\n",
    "        \n",
    "        sw_step_range = [i-1 for i in [1, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360]][::-1]\n",
    "        max_step_range = np.max(sw_step_range)\n",
    "        sw_labels = [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1][::-1]\n",
    "        event_switch =  np.zeros_like(target_binary)\n",
    "        for event in states[1:]:\n",
    "            event_idx = event[\"start\"]\n",
    "            event_switch[event_idx] = 1\n",
    "            for label_range, sw_label in zip(sw_step_range, sw_labels):\n",
    "                if min_duration < max_step_range:\n",
    "                    event_switch[max(event_idx - label_range, 0): min(event_idx + label_range+1, len(event_switch))] = np.maximum(event_switch[max(event_idx - label_range, 0): min(event_idx + label_range+1, len(event_switch))], sw_label)\n",
    "                else:\n",
    "                    event_switch[max(event_idx - label_range, 0): min(event_idx + label_range+1, len(event_switch))] = sw_label # np.maximum(event_switch[max(event_idx - label_range, 0): min(event_idx + label_range+1, len(event_switch))], sw_label)\n",
    "        \n",
    "        return event_switch\n",
    "\n",
    "    generated_array = blend_dataset(processed_array)\n",
    "    event_switch = remake_target(generated_array[:, -1])\n",
    "    # generated_array[:, -2]を差し換える\n",
    "    tmp = generated_array[:, -2].copy()\n",
    "    generated_array[:, -2] = event_switch\n",
    "\n",
    "    # 描画subplotで4つ\n",
    "    if plot:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(4,1,1)\n",
    "        plt.plot(generated_array[:, 1])\n",
    "        plt.subplot(4,1,2)\n",
    "        plt.plot(generated_array[:,-1])\n",
    "        plt.subplot(4,1,3)\n",
    "        plt.plot(tmp)\n",
    "        plt.subplot(4,1,4)\n",
    "        plt.plot(event_switch)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(4,1,1)\n",
    "        plt.plot(processed_array[:len(generated_array), 1])\n",
    "        plt.subplot(4,1,2)\n",
    "        plt.plot(processed_array[:len(generated_array),-1])\n",
    "        plt.subplot(4,1,3)\n",
    "        plt.plot(processed_array[:len(generated_array),-2])\n",
    "        plt.subplot(4,1,4)\n",
    "        plt.plot(processed_array[:len(generated_array),0])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    dummy_meta_data = {\"end_step_for_train\": len(generated_array)}\n",
    "    dummy_step = np.arange(len(generated_array))\n",
    "    np.save(file_path, generated_array)\n",
    "    np.save(file_step_path, dummy_step)\n",
    "    with open(file_path_meta, 'w') as f:\n",
    "        json.dump(dummy_meta_data, f, indent=4)\n",
    "\n",
    "    # return generated_array\n",
    "\n",
    "\n",
    "\n",
    "def make_dataset(df_train_id, df_target_id, id_no):\n",
    "    file_path = os.path.join(Cfg.preprocess_dir, f\"id_{id_no}_feature.npy\")\n",
    "    file_step_path = os.path.join(Cfg.preprocess_dir, f\"id_{id_no}_step.npy\")\n",
    "    file_path_meta = os.path.join(Cfg.preprocess_dir, f\"id_{id_no}_meta.json\")\n",
    "    train_columns = ['daily_step', 'anglez', 'anglez_simpleerror', 'anglez_simpleerror_span', \n",
    "    'anglez_nanexist', 'anglez_daystd', 'anglez_daymean', \"anglez_daycounter\", \"anglez_nancounter\", \n",
    "    'enmo', # \"accz\", \"accaxay\", # \"step_count\", \"dayofweek\", \n",
    "    'target_sw', 'target']\n",
    "    # with timer(f\"select_dataset {id_no}\"):\n",
    "    #     df_train_id, df_target_id = sample_train_target_by_id(df_train, df_target, id_no)\n",
    "    with timer(f\"timestamp_to_step {id_no}\"):\n",
    "        # df_train_id = timestamp_to_step(df_train_id)\n",
    "        # df_target_id = timestamp_to_step(df_target_id)\n",
    "        df_train_id, df_target_id = timestamp_to_step_single_id(df_train_id, df_target_id)\n",
    "    with timer(f\"make_binary_target {id_no}\"):\n",
    "        # df_train_id, end_step_for_train = make_binary_target(df_train_id, df_target_id, id_no)\n",
    "        df_train_id, end_step_for_train = make_multilabel_target(df_train_id, df_target_id, id_no)\n",
    "\n",
    "    with timer(f\"find_sensor_error {id_no}\"):\n",
    "        df_train_id = find_sensor_error(df_train_id, column='anglez')\n",
    "    df_train_id = make_features(df_train_id)\n",
    "    df_train_id = prerprocess_inputs_for_mlmodel(df_train_id)\n",
    "    meta_data = {\"end_step_for_train\": end_step_for_train}\n",
    "\n",
    "    # numpyに変換して保存する\n",
    "    np.save(file_path, df_train_id[train_columns].values)\n",
    "    np.save(file_step_path, df_train_id[\"step\"].values)\n",
    "    with open(file_path_meta, 'w') as f:\n",
    "        json.dump(meta_data, f, indent=4)\n",
    "        \n",
    "    \n",
    "\n",
    "def plot_train_target_by_id(df_train, df_target, id_no):\n",
    "    df_train_s, df_target_s = sample_train_target_by_id(df_train, df_target, id_no)\n",
    "    df_train_s = timestamp_to_step(df_train_s)\n",
    "    df_target_s = timestamp_to_step(df_target_s)\n",
    "    # trainはtimestampを横軸にしてanglezをプロット\n",
    "    # targetはtimestampを横軸にしてaxivlineで破線をひく\n",
    "    print(df_train_s.shape, df_target_s.shape)\n",
    "    df_train_s = find_sensor_error(df_train_s, column='anglez')\n",
    "    df_train_s = make_binary_target(df_train_s, df_target_s)\n",
    "    print(df_train_s.shape, df_target_s.shape)\n",
    "\n",
    "\n",
    "    x = df_train_s['daily_step'].values\n",
    "    y = df_train_s['anglez'].values\n",
    "    # n = df_train_s['anglez_simpleerror_v2'].values\n",
    "    n = df_train_s['target'].values\n",
    "    s = df_train_s['step'].values\n",
    "    # x,yをcfg.step_for_a_dayごとのindex長さに分割してプロットする\n",
    "    start = 0\n",
    "    end = int(Cfg.step_for_a_day) - int(x[0])\n",
    "    num_view = 10\n",
    "    \n",
    "    while end < len(x):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "        \n",
    "        start_step = s[start]\n",
    "        end_step = s[end]    \n",
    "        ax.plot(x[start:end], y[start:end])\n",
    "        ax.plot(x[start:end], 10*n[start:end])\n",
    "        \n",
    "\n",
    "        if num_view==5:\n",
    "            tmp5 = y[start:end]\n",
    "        if num_view==1:\n",
    "            tmp9 = y[start:end]\n",
    "\n",
    "        start = end\n",
    "        end += int(Cfg.step_for_a_day) \n",
    "\n",
    "\n",
    "\n",
    "        for total_step, event_step, event_type in zip(df_target_s['step'].values, df_target_s['daily_step'].values, df_target_s['event'].values):\n",
    "            if total_step < start_step:\n",
    "                continue\n",
    "            elif total_step > end_step:\n",
    "                break\n",
    "            if event_type == 'onset':\n",
    "                ax.axvline(event_step, color='red', linestyle='--')\n",
    "            elif event_type == 'wakeup':\n",
    "                ax.axvline(event_step, color='green', linestyle='--')\n",
    "        # x rangeは0~Cfg.step_for_a_day\n",
    "        ax.set_xlim(0, Cfg.step_for_a_day)\n",
    "        plt.show()\n",
    "        num_view -= 1\n",
    "        if num_view == 0:\n",
    "            break\n",
    "\n",
    "    return df_train_s, df_target_s\n",
    "\n",
    "\n",
    "def timestamp_to_step_single_id(df_train_id, df_target_id):\n",
    "    \"\"\"\n",
    "    Convert timestamp to step\n",
    "    timestepは2018-08-14T22:26:00-0400といった形で与えられる\n",
    "    これを午前0時開始の経過時間に変換し、5秒ごとのstepに変換する\n",
    "    idごとに処理する前提として、最初の時間をオフセットして、Cfg.daily_stepで割ってあまりをとる\n",
    "    \"\"\"\n",
    "    # iloc[0]で最初の時間を取得\n",
    "    offset_date = df_train_id['timestamp'].iloc[0:1].str.split('T', expand=True)[0]\n",
    "    offset_time = df_train_id['timestamp'].iloc[0:1].str.split('T', expand=True)[1].str.split('-', expand=True)[0]\n",
    "    offset = pd.to_datetime(offset_date + ' ' + offset_time)\n",
    "    offset_step = offset.dt.hour * 60 * 12 + offset.dt.minute * 12 + offset.dt.second / 5\n",
    "    df_train_id[\"daily_step\"] = (df_train_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
    "    df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
    "    df_train_id[\"dayofweek\"] = ((offset.dt.dayofweek.values[0] + (df_train_id['step'] + offset_step.values[0]) // Cfg.step_for_a_day)) % 7\n",
    "    # print((df['step'].iloc[-1] + offset_step) % Cfg.step_for_a_day)\n",
    "    return df_train_id, df_target_id\n",
    "\n",
    "# display(df_train_id.tail())\n",
    "# timestamp_to_step_single_id(df_train_id)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "- make fold no\n",
    "- split data for nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(Cfg.train_path)\n",
    "df_test = pd.read_parquet(Cfg.test_path)\n",
    "sample_submission = pd.read_csv(Cfg.sample_submission_path)\n",
    "df_target = pd.read_csv(Cfg.train_target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- make fold no split ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f547b8017d</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>fa149c3c4bde</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>fb223ed2278c</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>fcca183903b7</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        series_id  event\n",
       "0    038441c925bb     46\n",
       "1    03d92c9f6f8a     74\n",
       "2    0402a003dae9     48\n",
       "3    04f547b8017d     74\n",
       "4    05e1944c3818     16\n",
       "..            ...    ...\n",
       "272  fa149c3c4bde     48\n",
       "273  fb223ed2278c    106\n",
       "274  fbf33b1a2c10     48\n",
       "275  fcca183903b7     72\n",
       "276  fe90110788d2     70\n",
       "\n",
       "[277 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step_max</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>389879</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>724139</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>397259</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f547b8017d</td>\n",
       "      <td>637559</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>400859</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>fa149c3c4bde</td>\n",
       "      <td>406799</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>fb223ed2278c</td>\n",
       "      <td>918359</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>421019</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>fcca183903b7</td>\n",
       "      <td>620639</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>592379</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        series_id  step_max  event\n",
       "0    038441c925bb    389879     46\n",
       "1    03d92c9f6f8a    724139     74\n",
       "2    0402a003dae9    397259     48\n",
       "3    04f547b8017d    637559     74\n",
       "4    05e1944c3818    400859     16\n",
       "..            ...       ...    ...\n",
       "272  fa149c3c4bde    406799     48\n",
       "273  fb223ed2278c    918359    106\n",
       "274  fbf33b1a2c10    421019     48\n",
       "275  fcca183903b7    620639     72\n",
       "276  fe90110788d2    592379     70\n",
       "\n",
       "[277 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step_max</th>\n",
       "      <th>event</th>\n",
       "      <th>days</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>389879</td>\n",
       "      <td>46</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>724139</td>\n",
       "      <td>74</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>397259</td>\n",
       "      <td>48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f547b8017d</td>\n",
       "      <td>637559</td>\n",
       "      <td>74</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>400859</td>\n",
       "      <td>16</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>fa149c3c4bde</td>\n",
       "      <td>406799</td>\n",
       "      <td>48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>fb223ed2278c</td>\n",
       "      <td>918359</td>\n",
       "      <td>106</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>421019</td>\n",
       "      <td>48</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>fcca183903b7</td>\n",
       "      <td>620639</td>\n",
       "      <td>72</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>592379</td>\n",
       "      <td>70</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        series_id  step_max  event  days     ratio\n",
       "0    038441c925bb    389879     46  22.0  2.090909\n",
       "1    03d92c9f6f8a    724139     74  41.0  1.804878\n",
       "2    0402a003dae9    397259     48  22.0  2.181818\n",
       "3    04f547b8017d    637559     74  36.0  2.055556\n",
       "4    05e1944c3818    400859     16  23.0  0.695652\n",
       "..            ...       ...    ...   ...       ...\n",
       "272  fa149c3c4bde    406799     48  23.0  2.086957\n",
       "273  fb223ed2278c    918359    106  53.0  2.000000\n",
       "274  fbf33b1a2c10    421019     48  24.0  2.000000\n",
       "275  fcca183903b7    620639     72  35.0  2.057143\n",
       "276  fe90110788d2    592379     70  34.0  2.058824\n",
       "\n",
       "[277 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/utc/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/utc/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/utc/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/utc/lib/python3.9/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"--- make fold no split ---\")\n",
    "df_target = pd.read_csv(Cfg.train_target_path)\n",
    "\n",
    "\n",
    "max_step = df_train.groupby(\"series_id\")[\"step\"].max().reset_index().rename(columns={\"step\": \"step_max\"})\n",
    "df_train_target = pd.merge(df_target, max_step, on=\"series_id\", how=\"left\")\n",
    "df_train_target.loc[df_train_target[\"step\"].isnull(), \"event\"] = \"nan\"\n",
    "df_train_target[\"step\"] = df_train_target[\"step\"].fillna(1)\n",
    "df_train_target = df_train_target[df_train_target[\"step\"] < df_train_target[\"step_max\"]]\n",
    "df_train_target = df_train_target[df_train_target[\"step\"] > 0]\n",
    "#target_count = df_train_target[df_train_target[\"event\"].isin([\"onset\", \"wakeup\"])].groupby(\"series_id\")[\"event\"].count().reset_index()\n",
    "target_count = df_train_target.groupby(\"series_id\")[\"event\"].count().reset_index()\n",
    "\n",
    "display(target_count)\n",
    "\n",
    "df_train_target = pd.merge(max_step, target_count, on=\"series_id\", how=\"left\")\n",
    "df_train_target[\"event\"] = df_train_target[\"event\"].fillna(0)\n",
    "display(df_train_target)\n",
    "df_train_target[\"days\"] = df_train_target[\"step_max\"] // Cfg.step_for_a_day\n",
    "df_train_target[\"ratio\"] = df_train_target[\"event\"] / df_train_target[\"days\"]\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.scatter(df_train_target[\"event\"], df_train_target[\"days\"])\n",
    "# plt.show()\n",
    "# plt.hist(df_train_target[\"ratio\"], bins=100)\n",
    "# plt.show()\n",
    "\n",
    "display(df_train_target)\n",
    "\n",
    "# stratified k-foldを行う \n",
    "\n",
    "for seed in [111, 42]:\n",
    "    df_train_target[\"fold\"] = -1\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(df_train_target, (df_train_target[\"ratio\"].values//0.2).astype(int))):\n",
    "        df_train_target.loc[val_idx, \"fold\"] = fold\n",
    "    df_train_target.to_csv(os.path.join(Cfg.preprocess_dir, f\"series_id_5fold_seed{seed}.csv\"), index=False)\n",
    "\n",
    "    df_train_target[\"fold\"] = -1\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=111)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(df_train_target, (df_train_target[\"ratio\"].values//0.2).astype(int))):\n",
    "        df_train_target.loc[val_idx, \"fold\"] = fold\n",
    "    df_train_target.to_csv(os.path.join(Cfg.preprocess_dir, f\"series_id_2fold_seed{seed}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MEMUSE] memory usage (in before make_dataset): 4620.72MB (79.6%)\n",
      "038441c925bb\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 038441c925bb): 4638.31MB (82.8%)\n",
      "[timestamp_to_step 038441c925bb] 0.048sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 038441c925bb): 4632.80MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 038441c925bb): 4632.80MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 038441c925bb] 0.328sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 038441c925bb): 4668.00MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 038441c925bb): 4668.05MB (82.8%)\n",
      "[find_sensor_error 038441c925bb] 0.061sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 038441c925bb): 4673.48MB (82.9%)\n",
      "03d92c9f6f8a\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 03d92c9f6f8a): 4662.30MB (82.8%)\n",
      "[timestamp_to_step 03d92c9f6f8a] 0.016sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 03d92c9f6f8a): 4668.42MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 03d92c9f6f8a): 4668.44MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 03d92c9f6f8a] 0.282sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 03d92c9f6f8a): 4703.64MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 03d92c9f6f8a): 4703.64MB (82.9%)\n",
      "[find_sensor_error 03d92c9f6f8a] 0.163sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 03d92c9f6f8a): 4703.64MB (82.9%)\n",
      "0402a003dae9\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0402a003dae9): 4697.02MB (82.8%)\n",
      "[timestamp_to_step 0402a003dae9] 0.011sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0402a003dae9): 4703.94MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0402a003dae9): 4703.95MB (82.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0402a003dae9] 0.351sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0402a003dae9): 4717.14MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0402a003dae9): 4717.14MB (82.9%)\n",
      "[find_sensor_error 0402a003dae9] 0.036sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0402a003dae9): 4695.62MB (82.9%)\n",
      "04f547b8017d\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 04f547b8017d): 4695.62MB (82.9%)\n",
      "[timestamp_to_step 04f547b8017d] 0.015sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 04f547b8017d): 4695.62MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 04f547b8017d): 4695.62MB (82.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 04f547b8017d] 0.571sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 04f547b8017d): 4695.55MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 04f547b8017d): 4695.55MB (82.7%)\n",
      "[find_sensor_error 04f547b8017d] 0.067sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 04f547b8017d): 4689.53MB (82.7%)\n",
      "05e1944c3818\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 05e1944c3818): 4685.62MB (82.7%)\n",
      "[timestamp_to_step 05e1944c3818] 0.010sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 05e1944c3818): 4688.11MB (82.7%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 05e1944c3818): 4688.11MB (82.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 05e1944c3818] 0.123sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 05e1944c3818): 4689.52MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 05e1944c3818): 4689.52MB (82.7%)\n",
      "[find_sensor_error 05e1944c3818] 0.047sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 05e1944c3818): 4689.52MB (82.7%)\n",
      "062cae666e2a\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 062cae666e2a): 4689.52MB (82.7%)\n",
      "[timestamp_to_step 062cae666e2a] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 062cae666e2a): 4689.52MB (82.7%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 062cae666e2a): 4689.52MB (82.7%)\n",
      "[make_binary_target 062cae666e2a] 0.057sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 062cae666e2a): 4689.52MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 062cae666e2a): 4689.52MB (82.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[find_sensor_error 062cae666e2a] 0.048sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 062cae666e2a): 4689.52MB (82.7%)\n",
      "062dbd4c95e6\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 062dbd4c95e6): 4689.52MB (82.7%)\n",
      "[timestamp_to_step 062dbd4c95e6] 0.017sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 062dbd4c95e6): 4689.52MB (82.7%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 062dbd4c95e6): 4689.52MB (82.7%)\n",
      "[make_binary_target 062dbd4c95e6] 0.423sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 062dbd4c95e6): 4689.52MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 062dbd4c95e6): 4689.52MB (82.7%)\n",
      "[find_sensor_error 062dbd4c95e6] 0.133sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 062dbd4c95e6): 4438.09MB (81.6%)\n",
      "08db4255286f\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 08db4255286f): 4450.27MB (81.6%)\n",
      "[timestamp_to_step 08db4255286f] 0.010sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 08db4255286f): 4445.69MB (81.6%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 08db4255286f): 4445.69MB (81.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 08db4255286f] 0.444sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 08db4255286f): 4435.05MB (81.5%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 08db4255286f): 4435.05MB (81.5%)\n",
      "[find_sensor_error 08db4255286f] 0.032sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 08db4255286f): 4436.81MB (81.5%)\n",
      "0a96f4993bd7\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0a96f4993bd7): 4447.00MB (81.6%)\n",
      "[timestamp_to_step 0a96f4993bd7] 0.007sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0a96f4993bd7): 4447.00MB (81.6%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0a96f4993bd7): 4447.00MB (81.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0a96f4993bd7] 0.183sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0a96f4993bd7): 4447.00MB (81.6%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0a96f4993bd7): 4447.00MB (81.6%)\n",
      "[find_sensor_error 0a96f4993bd7] 0.018sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0a96f4993bd7): 4447.00MB (81.6%)\n",
      "0cd1e3d0ed95\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0cd1e3d0ed95): 4447.00MB (81.6%)\n",
      "[timestamp_to_step 0cd1e3d0ed95] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0cd1e3d0ed95): 4447.00MB (81.6%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0cd1e3d0ed95): 4447.00MB (81.6%)\n",
      "[make_binary_target 0cd1e3d0ed95] 0.097sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0cd1e3d0ed95): 4447.00MB (81.6%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0cd1e3d0ed95): 4447.00MB (81.6%)\n",
      "[find_sensor_error 0cd1e3d0ed95] 0.027sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0cd1e3d0ed95): 4447.00MB (81.6%)\n",
      "0ce74d6d2106\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0ce74d6d2106): 4447.00MB (81.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[timestamp_to_step 0ce74d6d2106] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0ce74d6d2106): 4447.00MB (81.6%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0ce74d6d2106): 4447.00MB (81.6%)\n",
      "[make_binary_target 0ce74d6d2106] 0.765sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0ce74d6d2106): 4560.50MB (82.2%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0ce74d6d2106): 4560.50MB (82.2%)\n",
      "[find_sensor_error 0ce74d6d2106] 0.080sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0ce74d6d2106): 4633.58MB (82.8%)\n",
      "0cfc06c129cc\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0cfc06c129cc): 4637.75MB (82.8%)\n",
      "[timestamp_to_step 0cfc06c129cc] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0cfc06c129cc): 4637.75MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0cfc06c129cc): 4637.75MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0cfc06c129cc] 0.339sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0cfc06c129cc): 4637.75MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0cfc06c129cc): 4637.75MB (82.8%)\n",
      "[find_sensor_error 0cfc06c129cc] 0.028sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0cfc06c129cc): 4637.75MB (82.8%)\n",
      "0d0ad1e77851\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0d0ad1e77851): 4637.75MB (82.8%)\n",
      "[timestamp_to_step 0d0ad1e77851] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0d0ad1e77851): 4637.75MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0d0ad1e77851): 4637.75MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0d0ad1e77851] 0.363sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0d0ad1e77851): 4637.75MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0d0ad1e77851): 4637.75MB (82.8%)\n",
      "[find_sensor_error 0d0ad1e77851] 0.032sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0d0ad1e77851): 4637.75MB (82.8%)\n",
      "0dee4fda51c3\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0dee4fda51c3): 4637.75MB (82.8%)\n",
      "[timestamp_to_step 0dee4fda51c3] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0dee4fda51c3): 4637.75MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0dee4fda51c3): 4637.75MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0dee4fda51c3] 0.349sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0dee4fda51c3): 4645.52MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0dee4fda51c3): 4645.55MB (82.8%)\n",
      "[find_sensor_error 0dee4fda51c3] 0.032sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0dee4fda51c3): 4651.27MB (82.8%)\n",
      "0ec9fc461819\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0ec9fc461819): 4639.53MB (82.8%)\n",
      "[timestamp_to_step 0ec9fc461819] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0ec9fc461819): 4639.25MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0ec9fc461819): 4639.25MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0ec9fc461819] 0.713sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0ec9fc461819): 4639.25MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0ec9fc461819): 4639.25MB (82.8%)\n",
      "[find_sensor_error 0ec9fc461819] 0.058sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0ec9fc461819): 4639.25MB (82.8%)\n",
      "0ef7d94fde99\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0ef7d94fde99): 4639.25MB (82.8%)\n",
      "[timestamp_to_step 0ef7d94fde99] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0ef7d94fde99): 4639.25MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0ef7d94fde99): 4639.25MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0ef7d94fde99] 0.392sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0ef7d94fde99): 4698.17MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0ef7d94fde99): 4698.17MB (82.9%)\n",
      "[find_sensor_error 0ef7d94fde99] 0.037sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0ef7d94fde99): 4706.11MB (82.9%)\n",
      "0f572d690310\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0f572d690310): 4698.50MB (82.9%)\n",
      "[timestamp_to_step 0f572d690310] 0.011sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0f572d690310): 4698.05MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0f572d690310): 4698.05MB (82.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 0f572d690310] 0.440sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0f572d690310): 4703.44MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0f572d690310): 4703.44MB (82.9%)\n",
      "[find_sensor_error 0f572d690310] 0.062sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0f572d690310): 4703.44MB (82.9%)\n",
      "0f9e60a8e56d\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 0f9e60a8e56d): 4703.44MB (82.9%)\n",
      "[timestamp_to_step 0f9e60a8e56d] 0.006sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 0f9e60a8e56d): 4703.44MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 0f9e60a8e56d): 4703.44MB (82.9%)\n",
      "[make_binary_target 0f9e60a8e56d] 0.000sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 0f9e60a8e56d): 4703.44MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 0f9e60a8e56d): 4703.44MB (82.9%)\n",
      "[find_sensor_error 0f9e60a8e56d] 0.017sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 0f9e60a8e56d): 4703.44MB (82.9%)\n",
      "10469f6765bf\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 10469f6765bf): 4703.44MB (82.9%)\n",
      "[timestamp_to_step 10469f6765bf] 0.010sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 10469f6765bf): 4703.44MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 10469f6765bf): 4703.44MB (82.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 10469f6765bf] 0.054sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 10469f6765bf): 4703.44MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 10469f6765bf): 4703.44MB (82.9%)\n",
      "[find_sensor_error 10469f6765bf] 0.042sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 10469f6765bf): 4703.44MB (82.9%)\n",
      "1087d7b0ff2e\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1087d7b0ff2e): 4703.44MB (82.9%)\n",
      "[timestamp_to_step 1087d7b0ff2e] 0.010sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1087d7b0ff2e): 4707.64MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1087d7b0ff2e): 4707.64MB (82.9%)\n",
      "[make_binary_target 1087d7b0ff2e] 0.442sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1087d7b0ff2e): 4702.94MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1087d7b0ff2e): 4702.94MB (82.9%)\n",
      "[find_sensor_error 1087d7b0ff2e] 0.035sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1087d7b0ff2e): 4702.94MB (82.9%)\n",
      "10f8bc1f7b07\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 10f8bc1f7b07): 4702.94MB (82.9%)\n",
      "[timestamp_to_step 10f8bc1f7b07] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 10f8bc1f7b07): 4702.94MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 10f8bc1f7b07): 4702.94MB (82.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 10f8bc1f7b07] 0.380sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 10f8bc1f7b07): 4702.94MB (82.9%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 10f8bc1f7b07): 4702.94MB (82.9%)\n",
      "[find_sensor_error 10f8bc1f7b07] 0.031sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 10f8bc1f7b07): 4702.94MB (82.9%)\n",
      "12d01911d509\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 12d01911d509): 4702.94MB (82.9%)\n",
      "[timestamp_to_step 12d01911d509] 0.018sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 12d01911d509): 4702.94MB (82.9%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 12d01911d509): 4702.94MB (82.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 12d01911d509] 0.759sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 12d01911d509): 4655.05MB (82.5%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 12d01911d509): 4655.05MB (82.5%)\n",
      "[find_sensor_error 12d01911d509] 0.120sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 12d01911d509): 4624.95MB (82.8%)\n",
      "1319a1935f48\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1319a1935f48): 4624.95MB (82.8%)\n",
      "[timestamp_to_step 1319a1935f48] 0.014sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1319a1935f48): 4624.95MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1319a1935f48): 4624.95MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1319a1935f48] 0.821sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1319a1935f48): 4618.06MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1319a1935f48): 4618.06MB (82.7%)\n",
      "[find_sensor_error 1319a1935f48] 0.075sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1319a1935f48): 4602.53MB (82.8%)\n",
      "137771d19ca2\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 137771d19ca2): 4612.38MB (82.8%)\n",
      "[timestamp_to_step 137771d19ca2] 0.010sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 137771d19ca2): 4613.56MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 137771d19ca2): 4613.56MB (82.8%)\n",
      "[make_binary_target 137771d19ca2] 0.073sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 137771d19ca2): 4614.47MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 137771d19ca2): 4614.47MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[find_sensor_error 137771d19ca2] 0.039sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 137771d19ca2): 4614.47MB (82.8%)\n",
      "137b99e936ab\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 137b99e936ab): 4614.47MB (82.8%)\n",
      "[timestamp_to_step 137b99e936ab] 0.012sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 137b99e936ab): 4614.47MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 137b99e936ab): 4614.47MB (82.8%)\n",
      "[make_binary_target 137b99e936ab] 0.457sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 137b99e936ab): 4614.47MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 137b99e936ab): 4614.47MB (82.8%)\n",
      "[find_sensor_error 137b99e936ab] 0.061sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 137b99e936ab): 4614.47MB (82.8%)\n",
      "13b4d6a01d27\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 13b4d6a01d27): 4614.47MB (82.8%)\n",
      "[timestamp_to_step 13b4d6a01d27] 0.010sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 13b4d6a01d27): 4614.47MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 13b4d6a01d27): 4614.47MB (82.8%)\n",
      "[make_binary_target 13b4d6a01d27] 0.072sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 13b4d6a01d27): 4614.47MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 13b4d6a01d27): 4614.47MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[find_sensor_error 13b4d6a01d27] 0.040sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 13b4d6a01d27): 4614.47MB (82.8%)\n",
      "148471991ffb\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 148471991ffb): 4614.47MB (82.8%)\n",
      "[timestamp_to_step 148471991ffb] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 148471991ffb): 4620.70MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 148471991ffb): 4620.70MB (82.8%)\n",
      "[make_binary_target 148471991ffb] 0.356sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 148471991ffb): 4625.45MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 148471991ffb): 4625.45MB (82.8%)\n",
      "[find_sensor_error 148471991ffb] 0.060sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 148471991ffb): 4629.56MB (82.8%)\n",
      "154fe824ed87\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 154fe824ed87): 4625.25MB (82.7%)\n",
      "[timestamp_to_step 154fe824ed87] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 154fe824ed87): 4625.25MB (82.7%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 154fe824ed87): 4625.25MB (82.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 154fe824ed87] 0.700sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 154fe824ed87): 4631.91MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 154fe824ed87): 4631.91MB (82.8%)\n",
      "[find_sensor_error 154fe824ed87] 0.051sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 154fe824ed87): 4629.50MB (82.8%)\n",
      "16fe2798ed0f\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 16fe2798ed0f): 4632.11MB (82.8%)\n",
      "[timestamp_to_step 16fe2798ed0f] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 16fe2798ed0f): 4634.77MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 16fe2798ed0f): 4634.77MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 16fe2798ed0f] 0.263sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 16fe2798ed0f): 4627.17MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 16fe2798ed0f): 4627.17MB (82.7%)\n",
      "[find_sensor_error 16fe2798ed0f] 0.029sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 16fe2798ed0f): 4627.17MB (82.7%)\n",
      "1716cd4163b2\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1716cd4163b2): 4627.17MB (82.7%)\n",
      "[timestamp_to_step 1716cd4163b2] 0.012sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1716cd4163b2): 4627.17MB (82.7%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1716cd4163b2): 4627.17MB (82.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1716cd4163b2] 0.514sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1716cd4163b2): 4627.17MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1716cd4163b2): 4627.17MB (82.7%)\n",
      "[find_sensor_error 1716cd4163b2] 0.050sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1716cd4163b2): 4627.17MB (82.7%)\n",
      "1762ab70ec76\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1762ab70ec76): 4613.16MB (82.6%)\n",
      "[timestamp_to_step 1762ab70ec76] 0.010sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1762ab70ec76): 4615.16MB (82.6%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1762ab70ec76): 4615.16MB (82.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1762ab70ec76] 0.352sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1762ab70ec76): 4615.16MB (82.6%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1762ab70ec76): 4615.16MB (82.6%)\n",
      "[find_sensor_error 1762ab70ec76] 0.034sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1762ab70ec76): 4615.16MB (82.6%)\n",
      "188d4b7cd28b\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 188d4b7cd28b): 4615.16MB (82.6%)\n",
      "[timestamp_to_step 188d4b7cd28b] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 188d4b7cd28b): 4615.16MB (82.6%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 188d4b7cd28b): 4615.16MB (82.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 188d4b7cd28b] 0.351sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 188d4b7cd28b): 4615.16MB (82.6%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 188d4b7cd28b): 4615.16MB (82.6%)\n",
      "[find_sensor_error 188d4b7cd28b] 0.031sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 188d4b7cd28b): 4615.16MB (82.6%)\n",
      "18a0ca03431d\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 18a0ca03431d): 4615.16MB (82.6%)\n",
      "[timestamp_to_step 18a0ca03431d] 0.014sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 18a0ca03431d): 4615.16MB (82.6%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 18a0ca03431d): 4615.16MB (82.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 18a0ca03431d] 0.734sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 18a0ca03431d): 4628.86MB (82.7%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 18a0ca03431d): 4628.86MB (82.7%)\n",
      "[find_sensor_error 18a0ca03431d] 0.074sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 18a0ca03431d): 4664.23MB (82.9%)\n",
      "18b61dd5aae8\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 18b61dd5aae8): 4680.97MB (83.0%)\n",
      "[timestamp_to_step 18b61dd5aae8] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 18b61dd5aae8): 4680.97MB (83.0%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 18b61dd5aae8): 4680.97MB (83.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 18b61dd5aae8] 0.689sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 18b61dd5aae8): 4680.97MB (83.0%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 18b61dd5aae8): 4680.97MB (83.0%)\n",
      "[find_sensor_error 18b61dd5aae8] 0.063sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 18b61dd5aae8): 4680.97MB (83.0%)\n",
      "1955d568d987\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1955d568d987): 4680.97MB (83.0%)\n",
      "[timestamp_to_step 1955d568d987] 0.014sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1955d568d987): 4680.97MB (83.0%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1955d568d987): 4680.97MB (83.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1955d568d987] 0.675sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1955d568d987): 4841.52MB (83.0%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1955d568d987): 4841.52MB (83.0%)\n",
      "[find_sensor_error 1955d568d987] 0.058sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1955d568d987): 4810.75MB (82.8%)\n",
      "1b92be89db4c\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1b92be89db4c): 4812.52MB (82.8%)\n",
      "[timestamp_to_step 1b92be89db4c] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1b92be89db4c): 4812.92MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1b92be89db4c): 4812.92MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1b92be89db4c] 0.350sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1b92be89db4c): 4812.92MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1b92be89db4c): 4812.92MB (82.8%)\n",
      "[find_sensor_error 1b92be89db4c] 0.031sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1b92be89db4c): 4812.92MB (82.8%)\n",
      "1c7c0bad1263\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1c7c0bad1263): 4812.92MB (82.8%)\n",
      "[timestamp_to_step 1c7c0bad1263] 0.004sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1c7c0bad1263): 4812.92MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1c7c0bad1263): 4812.92MB (82.8%)\n",
      "[make_binary_target 1c7c0bad1263] 0.046sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1c7c0bad1263): 4812.92MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1c7c0bad1263): 4812.92MB (82.8%)\n",
      "[find_sensor_error 1c7c0bad1263] 0.006sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1c7c0bad1263): 4812.92MB (82.8%)\n",
      "1d4569cbac0f\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1d4569cbac0f): 4812.92MB (82.8%)\n",
      "[timestamp_to_step 1d4569cbac0f] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1d4569cbac0f): 4812.92MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1d4569cbac0f): 4812.92MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n",
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1d4569cbac0f] 0.268sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1d4569cbac0f): 4812.92MB (82.8%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1d4569cbac0f): 4812.92MB (82.8%)\n",
      "[find_sensor_error 1d4569cbac0f] 0.057sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1d4569cbac0f): 4812.92MB (82.8%)\n",
      "1e6717d93c1d\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1e6717d93c1d): 4812.92MB (82.8%)\n",
      "[timestamp_to_step 1e6717d93c1d] 0.015sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1e6717d93c1d): 4812.92MB (82.8%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1e6717d93c1d): 4812.92MB (82.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1e6717d93c1d] 0.138sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1e6717d93c1d): 4732.70MB (82.3%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1e6717d93c1d): 4732.70MB (82.3%)\n",
      "[find_sensor_error 1e6717d93c1d] 0.048sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1e6717d93c1d): 4736.52MB (82.3%)\n",
      "1f96b9668bdf\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 1f96b9668bdf): 4722.73MB (82.2%)\n",
      "[timestamp_to_step 1f96b9668bdf] 0.013sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 1f96b9668bdf): 4715.44MB (82.2%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 1f96b9668bdf): 4715.44MB (82.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 1f96b9668bdf] 0.360sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 1f96b9668bdf): 4707.80MB (82.2%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 1f96b9668bdf): 4707.80MB (82.2%)\n",
      "[find_sensor_error 1f96b9668bdf] 0.054sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 1f96b9668bdf): 4710.25MB (82.1%)\n",
      "207eded97727\n",
      "[MEMUSE] memory usage (in before timestamp_to_step 207eded97727): 4704.78MB (82.1%)\n",
      "[timestamp_to_step 207eded97727] 0.009sec\n",
      "[MEMUSE] memory usage (in after timestamp_to_step 207eded97727): 4704.78MB (82.1%)\n",
      "[MEMUSE] memory usage (in before make_binary_target 207eded97727): 4704.78MB (82.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/l4mm8jf12n1_92fkw1fcm22h0000gn/T/ipykernel_8323/4087133321.py:572: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target_id[\"daily_step\"] = (df_target_id['step'] + offset_step.values[0]) % Cfg.step_for_a_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make_binary_target 207eded97727] 0.304sec\n",
      "[MEMUSE] memory usage (in after make_binary_target 207eded97727): 4704.78MB (82.1%)\n",
      "[MEMUSE] memory usage (in before find_sensor_error 207eded97727): 4704.78MB (82.1%)\n",
      "[find_sensor_error 207eded97727] 0.030sec\n",
      "[MEMUSE] memory usage (in after find_sensor_error 207eded97727): 4704.78MB (82.1%)\n",
      "debug mode. only 40 dataset. break\n",
      "[make_dataset] 29.238sec\n",
      "[MEMUSE] memory usage (in after make_dataset): 4704.78MB (82.1%)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with timer(\"make_dataset\"): # error at c8053490cec2, 'c908a0ad3e31'\n",
    "    for id_no, df_train_id in df_train.groupby('series_id'):\n",
    "        print(id_no)\n",
    "        df_target_id = df_target[df_target['series_id']==id_no]\n",
    "        #print(df_train_id['daily_step'].values)\n",
    "        #break\n",
    "        make_dataset(df_train_id, df_target_id, id_no)\n",
    "        # break\n",
    "        counter += 1\n",
    "\n",
    "        if Cfg.IS_DEBUG:\n",
    "            if counter > 40:\n",
    "                print(\"debug mode. only 40 dataset. break\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nseed_no = 42\\nnum_fold = 2\\nseries_fold = pd.read_csv(f\"../data/data_processed/series_id_{num_fold}fold_seed{seed_no}.csv\")\\nid2fold = {row[\"series_id\"]: row[\"fold\"] for i, row in series_fold.iterrows()}\\n\\nfiles = sorted(glob.glob(os.path.join(\"../data/data_processed\", \"*feature.npy\")))\\nfile_series_ids = [os.path.basename(f).split(\".\")[0].split(\"_\")[1] for f in files]\\nprint(len(id2fold))\\nprint(len(file_series_ids))\\nfile_fold = [id2fold[series_id] for series_id in file_series_ids]\\nfiles_train = [f for f, fold in zip(files, file_fold) if fold != 0]\\nfiles = [f for f, fold in zip(files, file_fold) if fold != 0] # train by generated data\\nprint(len(files), len(files_train))\\n\\n\\n\\nfor i in range(10):\\n    np.random.seed(i)\\n    shuffle_indices = np.arange(len(files))\\n    np.random.shuffle(shuffle_indices)\\n    shuffle_files = [files[i] for i in shuffle_indices]\\n    for f, f2 in zip(files, shuffle_files):\\n        id_no = f.split(\"id_\")[-1].split(\"_\")[0]\\n        id_no2 = f2.split(\"id_\")[-1].split(\"_\")[0]\\n        print(id_no)\\n        processed_array = np.load(f)\\n        second_array = np.load(f2)\\n\\n        generate_data(processed_array, id_no+\"W\"+id_no2, days_to_generate_ratio=0.2, min_split_minutes=60, max_split_minutes=240, save_dir=f\"../data/data_generated_f{num_fold}_s{seed_no}/\", plot=False, second_array=second_array, seed_no=i)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def regenerate_dataset(path, only_feature=False):\n",
    "    \"\"\"\n",
    "    pathにあるnpyファイル名を読み込み、ファイル名とデータ長のdictのリストを返す。\n",
    "    \"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(path, \"*feature.npy\")))\n",
    "    files_step = sorted(glob.glob(os.path.join(path, \"*step.npy\")))\n",
    "    files_meta = sorted(glob.glob(os.path.join(path, \"*meta.json\")))\n",
    "    dataset = []\n",
    "    for i, (file, file_step, file_meta) in enumerate(zip(files, files_step, files_meta)):\n",
    "        data = np.load(file)\n",
    "        meta = json.load(open(file_meta))\n",
    "        \n",
    "        #for i in range(5):\n",
    "        #    plt.plot(data[:7200, i])\n",
    "        #    plt.show()\n",
    "        #raise Exception\n",
    "        \n",
    "        #if only_feature:\n",
    "        #    dataset.append({\"file\": file, \"length\": data.shape[0], \"channel\": data.shape[1]})\n",
    "        #else:\n",
    "        \n",
    "        dataset.append({\"file\": file, \"file_step\": file_step, \"length\": data.shape[0], \"channel\": data.shape[1], \"end_step_for_train\": min(int(meta[\"end_step_for_train\"]), data.shape[0]), \"id_no\": i}) #id_for classificaiton\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "# DATA Generation did not work well\n",
    "\n",
    "\"\"\"\n",
    "seed_no = 42\n",
    "num_fold = 2\n",
    "series_fold = pd.read_csv(f\"../data/data_processed/series_id_{num_fold}fold_seed{seed_no}.csv\")\n",
    "id2fold = {row[\"series_id\"]: row[\"fold\"] for i, row in series_fold.iterrows()}\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(\"../data/data_processed\", \"*feature.npy\")))\n",
    "file_series_ids = [os.path.basename(f).split(\".\")[0].split(\"_\")[1] for f in files]\n",
    "print(len(id2fold))\n",
    "print(len(file_series_ids))\n",
    "file_fold = [id2fold[series_id] for series_id in file_series_ids]\n",
    "files_train = [f for f, fold in zip(files, file_fold) if fold != 0]\n",
    "files = [f for f, fold in zip(files, file_fold) if fold != 0] # train by generated data\n",
    "print(len(files), len(files_train))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    np.random.seed(i)\n",
    "    shuffle_indices = np.arange(len(files))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "    shuffle_files = [files[i] for i in shuffle_indices]\n",
    "    for f, f2 in zip(files, shuffle_files):\n",
    "        id_no = f.split(\"id_\")[-1].split(\"_\")[0]\n",
    "        id_no2 = f2.split(\"id_\")[-1].split(\"_\")[0]\n",
    "        print(id_no)\n",
    "        processed_array = np.load(f)\n",
    "        second_array = np.load(f2)\n",
    "\n",
    "        generate_data(processed_array, id_no+\"W\"+id_no2, days_to_generate_ratio=0.2, min_split_minutes=60, max_split_minutes=240, save_dir=f\"../data/data_generated_f{num_fold}_s{seed_no}/\", plot=False, second_array=second_array, seed_no=i)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
